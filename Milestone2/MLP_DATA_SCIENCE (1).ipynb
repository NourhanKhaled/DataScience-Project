{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_data_train = pd.read_csv('production_data_train.csv')\n",
    "prod_data_test = pd.read_csv('production_data_test.csv')\n",
    "ihs_data = pd.read_csv('IHS_data.csv')\n",
    "harmony_data = pd.read_csv('Harmony_data.csv')\n",
    "test_apis = pd.read_csv('test_APIs.csv', header=None)\n",
    "test_apis.columns = ['API']\n",
    "test_apis['API'] = (test_apis['API']).astype(str)\n",
    "test_apis['API'] = test_apis['API'].apply(lambda x: x.zfill(14))\n",
    "sample_file = pd.read_csv('sample_file.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(prod_data, wells_data, train):\n",
    "    prod_data = prod_data.drop_duplicates(subset=['API', 'Month', 'Year'], keep='last', inplace=False)\n",
    "    \n",
    "    # adding zeros to API\n",
    "    prod_data['API'] = (prod_data['API']).astype(str)\n",
    "    prod_data['API'] = prod_data['API'].apply(lambda x: x.zfill(14))\n",
    "    \n",
    "    # adding zeros to API\n",
    "    wells_data['API'] = (wells_data['API']).astype(str)\n",
    "    wells_data['API'] = wells_data['API'].apply(lambda x: x.zfill(14))\n",
    "    \n",
    "    # storing peak records \n",
    "    idx_max = prod_data.groupby(['API'])['Liquid'].transform('max') == prod_data['Liquid']\n",
    "    max_month_prod_data = prod_data[idx_max].drop_duplicates(subset='API', keep='first', inplace=False)\n",
    "    list_indices = ['API', 'Year', 'Month', 'Liquid']\n",
    "    max_month_prod_data = max_month_prod_data[list_indices]\n",
    "    max_month_prod_data = max_month_prod_data.rename(columns={\"Year\": \"Max_Year\", \"Month\": \"Max_Month\", \"Liquid\": \"Max_Liquid\"})\n",
    "    \n",
    "    # merging the two dataframes to get max month and max year\n",
    "    new_prod_data_orig = prod_data.merge(max_month_prod_data, on='API')\n",
    "#     print(new_prod_data_orig['API'].drop_duplicates())\n",
    "    # Remove Pre-Peak Months (clean up)\n",
    "    new_prod_data = new_prod_data_orig[((new_prod_data_orig['Year'] == new_prod_data_orig['Max_Year']))]\n",
    "    new_prod_data = new_prod_data[(new_prod_data['Month'] >= new_prod_data['Max_Month'])]\n",
    "\n",
    "    new_prod_data2 = new_prod_data_orig[((new_prod_data_orig['Year'] > new_prod_data_orig['Max_Year']))]\n",
    "    new_prod_data3 = new_prod_data.append(new_prod_data2)\n",
    "    # adding month index column to post peak production data\n",
    "    new_prod_data3['index'] = calc_month_index(new_prod_data3['Max_Year'], new_prod_data3['Max_Month'], new_prod_data3['Year'], new_prod_data3['Month'])\n",
    "    indexed_prod_data = new_prod_data3\n",
    "    \n",
    "    # removed nullified SpudDates and CompletionDates\n",
    "    wells_data = wells_data[~((wells_data['SpudDate'].isnull()) & (wells_data['CompletionDate'].isnull()))]\n",
    "    \n",
    "    # replacing null CompletionDates with SpudDates + six months\n",
    "    wells_data['SpudDate'] = pd.to_datetime(wells_data['SpudDate'])\n",
    "    wells_data['CompletionDate'] = pd.to_datetime(wells_data['CompletionDate'])\n",
    "    wells_data.loc[wells_data['CompletionDate'].isnull(), 'CompletionDate'] = wells_data['SpudDate'] + timedelta(days=170) \n",
    "    \n",
    "    # replacing StateNames with indices\n",
    "    unique_state_names = wells_data.StateName.unique()\n",
    "    unique_state_ids = list(range(0, len(unique_state_names)))\n",
    "    dict_state_names = dict(zip( unique_state_names, unique_state_ids))\n",
    "    wells_data['StateName'] = wells_data['StateName'].map(dict_state_names)\n",
    "                            \n",
    "    # replacing CountyNames with indices                         \n",
    "    unique_county_names = wells_data.CountyName.unique()\n",
    "    unique_county_ids = list(range(0, len(unique_county_names)))\n",
    "    dict_county_names = dict(zip(unique_county_names, unique_county_ids))\n",
    "    wells_data['CountyName'] = wells_data['CountyName'].map(dict_county_names)\n",
    "    \n",
    "    # replacing BasinName with indices\n",
    "    unique_basin_names = wells_data.BasinName.unique()\n",
    "    unique_basin_ids = list(range(0, len(unique_basin_names)))\n",
    "    dict_basin_names = dict(zip(unique_basin_names, unique_basin_ids))\n",
    "    wells_data['BasinName'] = wells_data['BasinName'].map(dict_basin_names)\n",
    "    \n",
    "    #replacing Formation with indices\n",
    "    unique_formation_names = wells_data.formation.unique()\n",
    "    unique_formation_ids = list(range(0, len(unique_formation_names)))\n",
    "    dict_formation_names = dict(zip(unique_formation_names, unique_formation_ids))\n",
    "    wells_data['formation'] = wells_data['formation'].map(dict_formation_names)\n",
    "        \n",
    "#     wells_data[wells_data['CompletionDate'] >= pd.Timestamp(2014, 1 , 1)]['CompletionDate'] = 1  \n",
    "#     wells_data[wells_data['CompletionDate'] !=  1]['CompletionDate'] = 0 \n",
    "#     print(wells_data[wells_data['CompletionDate'] < pd.Timestamp(2014, 1 , 1)])\n",
    "\n",
    "    indexed_prod_data = indexed_prod_data.merge(wells_data, on='API')\n",
    "    three_years_data = indexed_prod_data\n",
    "    if(train):\n",
    "        three_years_data = indexed_prod_data[(indexed_prod_data['Max_Year'] < 2016) |((indexed_prod_data['Max_Year'] == 2016) & (indexed_prod_data['Max_Month'] == 1))] \n",
    "        three_years_data = three_years_data[three_years_data['index'] <= 36] \n",
    "    \n",
    "    return three_years_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates month index\n",
    "def calc_month_index(max_year, max_month, year, month):\n",
    "    return (12 - max_month + (year - max_year - 1)*12 + month) * (year != max_year) + (year == max_year) * (month - max_month) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nourhan Khaled\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Nourhan Khaled\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Nourhan Khaled\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Nourhan Khaled\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "processed_train = preprocess(prod_data_train, ihs_data, True)\n",
    "processed_test = preprocess(prod_data_test, ihs_data, False)\n",
    "\n",
    "harmony_data['API'] = (harmony_data['API']).astype(str)\n",
    "harmony_data['API'] = harmony_data['API'].apply(lambda x: x.zfill(14))\n",
    "\n",
    "harmony_data[harmony_data['WATER_PER_FOOT'].isnull()]['WATER_PER_FOOT'] = harmony_data['WATER_PER_FOOT'].mode()\n",
    "harmony_data[harmony_data['PROP_PER_FOOT'].isnull()]['PROP_PER_FOOT'] = harmony_data['PROP_PER_FOOT'].mode()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complete_prod_train = processed_train.merge(harmony_data, on='API')\n",
    "complete_prod_test = processed_test.merge(harmony_data, on='API', how='outer')\n",
    "complete_prod_test.fillna(0, inplace=True)\n",
    "complete_prod_test = complete_prod_test.merge(test_apis, on='API')\n",
    "# removing production of month index greater that 3\n",
    "# # complete_prod_test = complete_prod_test[complete_prod_test['index'] <= 3]\n",
    "# complete_prod_test[complete_prod_test['GOR_30'].isnull()]['GOR_30'] = complete_prod_test['GOR_30'].mode()\n",
    "# complete_prod_test[complete_prod_test['GOR_60'].isnull()]['GOR_60'] = complete_prod_test['GOR_60'].mode()\n",
    "# complete_prod_test[complete_prod_test['GOR_90'].isnull()]['GOR_90'] = complete_prod_test['GOR_90'].mode()\n",
    "\n",
    "# # replacing gor nans with zeros\n",
    "# complete_prod_train[complete_prod_train['GOR_30'].isnull()]['GOR_30'] = complete_prod_train['GOR_30'].mode()\n",
    "# complete_prod_train[complete_prod_train['GOR_60'].isnull()]['GOR_60'] = complete_prod_train['GOR_60'].mode()\n",
    "# complete_prod_train[complete_prod_train['GOR_90'].isnull()]['GOR_90'] = complete_prod_train['GOR_90'].mode()\n",
    "complete_prod_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = ['Gas', 'Water', 'Max_Year','operatorNameIHS', 'CompletionDate', 'FirstProductionDate', 'Max_Liquid', \n",
    "              'Max_Month', 'SpudDate', 'PermitDate', '_LastUpdate','BasinName', 'StateName', 'CountyName', 'DaysOn']\n",
    "cols_test = ['Gas', 'date', 'Water', 'Max_Year','operatorNameIHS', 'CompletionDate', 'FirstProductionDate', 'Max_Liquid',\n",
    "             'Max_Month', 'SpudDate', 'PermitDate', '_LastUpdate', 'BasinName', 'StateName','CountyName', 'DaysOn']\n",
    "complete_prod_train = complete_prod_train.drop(cols_train, axis=1)\n",
    "complete_prod_test = complete_prod_test.drop(cols_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_prod_test['API'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input first three months and y label is cumulative\n",
    "# predict missing entries in test data by averaging\n",
    "# in train disregard qthings with less than 36\n",
    "testing_apis = []\n",
    "def get_three_months(prod_data, feat_arr, y_label, test):\n",
    "    prod_data = (prod_data.groupby('API').apply(generate_input, feat_arr, y_label, test))\n",
    "    \n",
    "def generate_input(group, feat_arr, y_label, test):\n",
    "    global testing_apis\n",
    "    y_label.append(group['Liquid'].sum())\n",
    "    testing_apis.append(group['API'].max())\n",
    "    if len(group) < 2:\n",
    "        print(\"API\", group['API'])\n",
    "        \n",
    "    group = group.drop(['API'], axis=1)\n",
    "    records = group[:3]\n",
    "        \n",
    "    if len(records) == 3 and not test:\n",
    "        feat_arr.append(list(np.array(records).flatten()))\n",
    "        \n",
    "    elif test and len(records) < 3:\n",
    "        idx_1 = records[records['index'] == 1]\n",
    "        idx_2 = records[records['index'] == 2]\n",
    "        idx_3 = records[records['index'] == 3]\n",
    "                \n",
    "        print((idx_1['Liquid']).values[0])\n",
    "\n",
    "        # case 2, idx 2 missing\n",
    "        missing_rec = idx_1\n",
    "        missing_rec['Liquid'] =  (idx_1['Liquid'].values[0] + idx_3['Liquid'].values[0])/2\n",
    "        missing_rec['index'] = 2\n",
    "        arr = np.vstack((idx_1, missing_rec, idx_3))\n",
    "        feat_arr.append(list(arr.flatten()))\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        feat_arr.append(list(np.array(records).flatten()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feats = []\n",
    "y_labels = []\n",
    "get_three_months(complete_prod_train, input_feats, y_labels, False)\n",
    "valid_dataset = []\n",
    "input_feats = np.array(input_feats)\n",
    "y_labels = np.array(y_labels)\n",
    "# print(\"before validation split\", input_feats.shape)\n",
    "# (input_feats, X_valid) = input_feats[2000:], input_feats[:2000]\n",
    "# (y_labels, Y_valid) = y_labels[2000:], y_labels[:2000]\n",
    "# print(\"after validation split\", input_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2814.0\n",
      "11364.0\n",
      "7317.0\n",
      "6478.0\n",
      "14756.0\n",
      "12777.0\n",
      "7473.0\n",
      "7043.0\n",
      "9490.0\n",
      "10421.0\n",
      "7802.0\n",
      "3730.0\n",
      "6156.0\n",
      "7993.0\n",
      "10468.0\n",
      "10832.0\n",
      "11330.0\n",
      "7520.0\n",
      "7992.0\n",
      "10120.0\n",
      "7938.0\n",
      "6067.0\n",
      "20730.0\n",
      "9485.0\n",
      "4525.0\n",
      "5671.0\n",
      "4241.0\n",
      "5869.0\n",
      "10874.0\n",
      "9387.0\n",
      "7920.0\n",
      "4627.0\n",
      "6458.0\n",
      "8153.0\n",
      "5218.0\n",
      "14074.0\n",
      "6247.0\n",
      "6546.0\n",
      "12381.0\n",
      "10022.0\n",
      "8671.0\n",
      "9648.0\n",
      "4824.0\n",
      "11068.0\n",
      "10138.0\n",
      "5736.0\n",
      "6677.0\n",
      "8363.0\n",
      "12081.0\n",
      "9211.0\n",
      "10572.0\n",
      "13324.0\n",
      "3859.0\n",
      "4419.0\n",
      "6974.0\n",
      "9938.0\n",
      "38207.0\n",
      "12568.0\n",
      "19427.0\n",
      "10561.0\n",
      "16559.0\n",
      "6719.0\n",
      "25418.0\n",
      "7508.0\n",
      "13461.0\n",
      "2453.0\n",
      "28747.0\n",
      "18801.0\n",
      "15795.0\n",
      "4596.0\n",
      "18120.0\n",
      "10034.0\n",
      "40083.0\n",
      "21330.0\n",
      "11281.0\n",
      "18783.0\n",
      "15681.0\n",
      "8411.0\n",
      "14824.0\n",
      "25948.0\n",
      "12834.0\n",
      "15688.0\n",
      "5837.0\n",
      "16873.0\n",
      "25317.0\n",
      "48604.0\n",
      "16546.0\n",
      "8751.0\n",
      "15324.0\n",
      "15394.0\n",
      "14867.0\n",
      "19821.0\n",
      "27481.0\n",
      "15885.0\n",
      "2716.0\n",
      "3773.0\n",
      "7179.0\n",
      "9766.0\n",
      "8986.0\n",
      "8871.0\n",
      "4988.0\n",
      "10687.0\n",
      "7670.0\n",
      "7890.0\n",
      "10696.0\n",
      "7607.0\n",
      "19218.0\n",
      "33038.0\n",
      "27769.0\n",
      "14805.0\n",
      "40901.0\n",
      "24960.0\n",
      "20297.0\n",
      "13711.0\n",
      "20348.0\n",
      "13266.0\n",
      "12708.0\n",
      "17030.0\n",
      "14930.0\n",
      "10095.0\n",
      "10775.0\n",
      "17734.0\n",
      "25817.0\n",
      "23381.0\n",
      "15235.0\n",
      "38201.0\n",
      "7722.0\n",
      "15385.0\n",
      "19370.0\n",
      "6496.0\n",
      "26037.0\n",
      "21684.0\n",
      "32108.0\n",
      "13935.0\n",
      "23140.0\n",
      "19669.0\n",
      "8328.0\n",
      "5870.0\n",
      "17560.0\n",
      "20770.0\n",
      "17571.0\n",
      "2783.0\n",
      "20816.0\n",
      "25003.0\n",
      "16642.0\n",
      "17022.0\n",
      "12173.0\n",
      "19426.0\n",
      "14620.0\n",
      "13111.0\n",
      "8321.0\n",
      "38425.0\n",
      "26382.0\n",
      "16902.0\n",
      "8079.0\n",
      "22082.0\n",
      "27267.0\n",
      "6989.0\n",
      "16126.0\n",
      "20769.0\n",
      "15873.0\n",
      "27062.0\n",
      "25606.0\n",
      "38553.0\n",
      "14975.0\n",
      "39484.0\n",
      "33389.0\n",
      "9694.0\n",
      "9282.0\n",
      "20517.0\n",
      "23770.0\n",
      "16658.0\n",
      "21417.0\n",
      "24692.0\n",
      "8365.0\n",
      "45145.0\n",
      "15639.0\n",
      "20132.0\n",
      "12987.0\n",
      "17428.0\n",
      "15874.0\n",
      "17440.0\n",
      "10930.0\n",
      "15104.0\n",
      "20571.0\n",
      "33876.0\n",
      "17544.0\n",
      "12915.0\n",
      "14270.0\n",
      "21116.0\n",
      "11027.0\n",
      "15243.0\n",
      "7284.0\n",
      "15421.0\n",
      "9690.0\n",
      "17921.0\n",
      "24741.0\n",
      "16725.0\n",
      "11789.0\n",
      "10353.0\n",
      "29601.0\n",
      "15002.0\n",
      "18722.0\n",
      "26543.0\n",
      "4355.0\n",
      "30080.0\n",
      "19836.0\n",
      "13028.0\n",
      "21952.0\n",
      "23588.0\n",
      "20528.0\n",
      "11948.0\n",
      "5852.0\n",
      "20731.0\n",
      "23202.0\n",
      "17801.0\n",
      "15196.0\n",
      "22374.0\n",
      "12418.0\n",
      "15083.0\n",
      "16984.0\n",
      "13683.0\n",
      "9875.0\n",
      "15701.0\n",
      "10725.0\n",
      "10733.0\n",
      "14715.0\n",
      "9469.0\n",
      "22345.0\n",
      "26384.0\n",
      "6363.0\n",
      "8874.0\n",
      "23689.0\n",
      "14119.0\n",
      "18312.0\n",
      "10610.0\n",
      "22696.0\n",
      "20618.0\n",
      "11358.0\n",
      "12153.0\n",
      "17287.0\n",
      "8078.0\n",
      "16274.0\n",
      "5102.0\n",
      "8951.0\n",
      "17803.0\n",
      "24958.0\n",
      "26101.0\n",
      "11612.0\n",
      "11317.0\n",
      "13727.0\n",
      "15250.0\n",
      "16259.0\n",
      "14095.0\n",
      "6931.0\n",
      "15038.0\n",
      "5496.0\n",
      "5126.0\n",
      "1161.0\n",
      "59084.0\n",
      "9288.0\n",
      "2446.0\n",
      "7979.0\n",
      "7689.0\n",
      "5167.0\n",
      "15704.0\n",
      "3811.0\n",
      "11014.0\n",
      "18107.0\n",
      "850.0\n",
      "4454.0\n",
      "6783.0\n",
      "8869.0\n",
      "5334.0\n",
      "5989.0\n",
      "32858.0\n",
      "19456.0\n",
      "7802.0\n",
      "17591.0\n",
      "19925.0\n",
      "7737.0\n",
      "7367.0\n",
      "7466.0\n",
      "15700.0\n",
      "10599.0\n",
      "29533.0\n",
      "10233.0\n",
      "10124.0\n",
      "8566.0\n",
      "12451.0\n",
      "9958.0\n",
      "9227.0\n",
      "9349.0\n",
      "6399.0\n",
      "12260.0\n",
      "13806.0\n",
      "17170.0\n",
      "13454.0\n",
      "14240.0\n",
      "18912.0\n",
      "11445.0\n",
      "6262.0\n",
      "12332.0\n",
      "7742.0\n",
      "4404.0\n",
      "25008.0\n",
      "13666.0\n",
      "6212.0\n",
      "10270.0\n",
      "10825.0\n",
      "12824.0\n",
      "18380.0\n",
      "15359.0\n",
      "29878.0\n",
      "2554.0\n",
      "8547.0\n",
      "8386.0\n",
      "9187.0\n",
      "6707.0\n",
      "11116.0\n",
      "9525.0\n",
      "1130.0\n",
      "4832.0\n",
      "19287.0\n",
      "13685.0\n",
      "7338.0\n",
      "7967.0\n",
      "32059.0\n",
      "7900.0\n",
      "16151.0\n",
      "15719.0\n",
      "20759.0\n",
      "27147.0\n",
      "10579.0\n",
      "20459.0\n",
      "20624.0\n",
      "19941.0\n",
      "8351.0\n",
      "6658.0\n",
      "8520.0\n",
      "15470.0\n",
      "6771.0\n",
      "12241.0\n",
      "15549.0\n",
      "16160.0\n",
      "6150.0\n",
      "4532.0\n",
      "3667.0\n",
      "20293.0\n",
      "9154.0\n",
      "4662.0\n",
      "21222.0\n",
      "16325.0\n",
      "14037.0\n",
      "16643.0\n",
      "7048.0\n",
      "17613.0\n",
      "9272.0\n",
      "22628.0\n",
      "16239.0\n",
      "14373.0\n",
      "20948.0\n",
      "10866.0\n",
      "12945.0\n",
      "25011.0\n",
      "22869.0\n",
      "15301.0\n",
      "18393.0\n",
      "14376.0\n",
      "9334.0\n",
      "8053.0\n",
      "9304.0\n",
      "24517.0\n",
      "9809.0\n",
      "14119.0\n",
      "16477.0\n",
      "17267.0\n",
      "21060.0\n",
      "16326.0\n",
      "5511.0\n",
      "11037.0\n",
      "6595.0\n"
     ]
    }
   ],
   "source": [
    "# prepare testing data\n",
    "x_test = []\n",
    "testing_apis = []\n",
    "get_three_months(complete_prod_test, x_test, [], True)\n",
    "testing_apis = testing_apis[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = MLPRegressor(hidden_layer_sizes=(50,50), activation='relu', solver='adam', \n",
    "                         alpha=0.0001, batch_size='auto',\n",
    "                         learning_rate_init=0.001, power_t=0.5, max_iter=200, \n",
    "                         shuffle=True, random_state=None, tol=0.0001, verbose=False, \n",
    "                         warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                         early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                         epsilon=1e-08)\n",
    "regressor.fit(input_feats, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions = predictions[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(testing_apis)):\n",
    "    data.append([testing_apis[i], predictions[i]])\n",
    "output_df = pd.DataFrame(data, columns = ['Id', 'Predicted'])\n",
    "output_df.to_csv('three_yrs_cum.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3331"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
